{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Global definitions\n",
    "\n",
    "Load Pylab, define CPTs..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "%pylab inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.73  0.27]\n",
      "[ 0.611  0.389]\n",
      "[[ 0.2288743  0.7711257]]\n"
     ]
    }
   ],
   "source": [
    "# Define the CPTs and other useful functions here (e.g. samling from a distribution) here...\n",
    "POB = array([[[0.01, 0.7], \n",
    "               [0.99, 0.3] ],\n",
    "            [[0.8, 0.999],\n",
    "            [0.2, 0.001]]])\n",
    "O_PB = POB.transpose(1, 0, 2)\n",
    "#print BO[0,0,1]\n",
    "#print O_PB[0,0,1]\n",
    "\n",
    "T_P = array([[0.8, 0.1],\n",
    "             [0.2, 0.9]])\n",
    "#print T_P[1,0]\n",
    "P_L = T_P.copy()  #copy array and not reference # TODO\n",
    "#print P_L[0,1]\n",
    "L = array([0.9, 0.1])\n",
    "B = array([0.99, 0.01])\n",
    "#print random.sample(10)\n",
    "O_PB2 = O_PB.cumsum()\n",
    "#print O_PB2\n",
    "#print O_PB2.searchsorted(random.sample(10))\n",
    "\n",
    "PL = P_L * L\n",
    "#print PL\n",
    "#l = L.cumsum().searchsorted(1.1)\n",
    "#print l\n",
    "T = empty([1, 2])\n",
    "O = empty([1, 2])\n",
    "P = empty([1, 2])\n",
    "\n",
    "#print P\n",
    "###########new empty array # TODO\n",
    "#P[0] =1\n",
    "#P[1] = 2\n",
    "#print P\n",
    "#print L\n",
    "#print T\n",
    "#print O\n",
    "#P[0] = L[0] * P_L[0, 0] + L[1] * P_L[0, 1]\n",
    "#P[1] = L[0] * P_L[1, 0] + L[1] * P_L[1, 1]\n",
    "P = (P_L * L).sum(1)\n",
    "print P\n",
    "#print \n",
    "\n",
    "T = (T_P * P).sum(1)\n",
    "print T\n",
    "\n",
    "\n",
    "O[0,0] = P[0] * B[0] * O_PB[0, 0, 0] + P[1] * B[0] * O_PB[0, 1, 0] + P[0] * B[1] * O_PB[0, 0, 1] + P[1] * B[1] * O_PB[0, 1, 1]\n",
    "O[0,1] = P[0] * B[0] * O_PB[1, 0, 0] + P[1] * B[0] * O_PB[1, 1, 0] + P[0] * B[1] * O_PB[1, 0, 1] + P[1] * B[1] * O_PB[1, 1, 1]\n",
    "\n",
    "print O"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1) Approximate Inference Algorithms\n",
    "\n",
    "Approximate $P(E\\mid M, S)$ using various techniques."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A) Rejection Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def approx_rs(t, o, n):\n",
    "    \"\"\" \n",
    "    Approximates P(L | T, O) using rejection sampling\n",
    "    :param t: given value for T\n",
    "    :param o: given value for O\n",
    "    :param n: number of samples to use\n",
    "    :returns: Numpy array containing the approximated distribution\n",
    "    \"\"\"\n",
    "    # TODO: implement this function\n",
    "    \n",
    "    counter = 0.0\n",
    "    \n",
    "    for x in range(n):\n",
    "        #print x\n",
    "        tx = random.sample(1)\n",
    "        ox = random.sample(1)\n",
    "        tra = T.cumsum().searchsorted(tx)[0]  #position, not value\n",
    "        ora = O.cumsum().searchsorted(ox)[0] #position, not value\n",
    "        \n",
    "        if (tra == t and ora == o) :      \n",
    "            #print 'test'\n",
    "            lx = random.sample(1)\n",
    "            bx = random.sample(1)\n",
    "            px = random.sample(1)\n",
    "            lra = L.cumsum().searchsorted(lx)[0]  #position, not value\n",
    "               # P[0] = L[l] * P_L[0, l]\n",
    "            # P[1] = L[l] * P_L[1, l]\n",
    "            bra = B.cumsum().searchsorted(bx)[0]  #position, not value\n",
    "            pra = P.cumsum().searchsorted(px)[0]  #position, not value\n",
    "            #print pra\n",
    "            #T[0] = T[p] * T_P[0, p]\n",
    "            #T[1] = T[p] * T_P[1, p]\n",
    "            l_to = L[lra] * P_L[pra, lra] * B[bra] * T_P[tra, pra] * O_PB[ora, pra, bra] #value, not position\n",
    "            #print l_to\n",
    "            lcalc = L.cumsum().searchsorted(l_to)\n",
    "            #print lcalc\n",
    "            if lcalc == 0 :\n",
    "                counter += 1\n",
    "    \n",
    "    \n",
    "    l0_TO = counter / n\n",
    "    \n",
    "    print [l0_TO, 1 - l0_TO]\n",
    "    return [l0_TO, 1 - l0_TO]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## B) Likelihood Weighting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def approx_lw(t, o, n):\n",
    "    \"\"\"\n",
    "    Empty implementation of Aiv)\n",
    "    Approximates P(L | T, O) using likelihood weighting\n",
    "    :param t: given value for T\n",
    "    :param o: given value for O\n",
    "    :param n: number of samples to use\n",
    "    :returns: Numpy array containing the approximated distribution\n",
    "    \"\"\"\n",
    "    # TODO: implement this function\n",
    "    l0 = 0.0\n",
    "    l1 = 0.0\n",
    "    \n",
    "    for x in range(n):\n",
    "        bx = random.sample(1)\n",
    "        px = random.sample(1)  \n",
    "        bra = B.cumsum().searchsorted(bx)[0]  #position, not value\n",
    "        pra = P.cumsum().searchsorted(px)[0]  #position, not value\n",
    "        l0 += P_L[pra, 0] * T_P[t, pra] * O_PB[o, pra, bra]\n",
    "        l1 += P_L[pra, 1] * T_P[t, pra] * O_PB[o, pra, bra]\n",
    "    \n",
    "    ltot = l0 + l1\n",
    "    \n",
    "    #print [l0/ltot, l1/ltot]\n",
    "    return [l0/ltot, l1/ltot]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## C) Gibbs Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def approx_gibbs(t, o, n):\n",
    "    \"\"\" \n",
    "    Approximates P(L | T, O) using Gibbs sampling\n",
    "    :param t: given value for T\n",
    "    :param o: given value for O\n",
    "    :param n: number of samples to use\n",
    "    :returns: Numpy array containing the approximated distribution\n",
    "    \"\"\"\n",
    "    # TODO: implement this function\n",
    "    return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2) Comparison\n",
    "\n",
    "## A) Exact Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def exact(t, o):\n",
    "    \"\"\" \n",
    "    Computes P(L | T, O) using exact inference\n",
    "    :param t: given value for T\n",
    "    :param o: given value for O\n",
    "    :returns: Numpy array containing the distribution\n",
    "    \"\"\"\n",
    "    # TODO: implement this function\n",
    "    return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## B) Compute and plot estimation errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def kld(p, q):\n",
    "    \"\"\"\n",
    "    Computes the Kullback-Leibler divergence between p and q.\n",
    "    :param p: true distribution\n",
    "    :param q: estimated distribution\n",
    "    :return: Kullback-Leibler Divergence between p and q\n",
    "    \"\"\"\n",
    "    return (p * np.log(p / (q + 0.00000000001))).sum()  # add a small constant for numeric stability\n",
    "\n",
    "\n",
    "def compute_approximation_error(approx_function, t, o, n_runs, sample_counts, **kwargs):\n",
    "    \"\"\"\n",
    "    Computes the approximation error for a given approximation method.\n",
    "    :param approx_function: function used to approximate the distribution\n",
    "    :param t: given value for T\n",
    "    :param o: given value for O\n",
    "    :param n_runs: number of approximations\n",
    "    :param sample_counts: list or array of numbers of sampels to use\n",
    "    :returns: mean approximation error for each of the sample counts\n",
    "    \"\"\"\n",
    "    mean_errors = []\n",
    "    correct = exact(t, o)\n",
    "    \n",
    "    for num_samples in sample_counts:\n",
    "        estimates = array([approx_function(t, o, n=num_samples, **kwargs) for i in range(n_runs)])\n",
    "        mean_errors.append(abs(estimates - correct).mean())       \n",
    "        #mean_errors.append(kld(correct, estimates))  # use this instead of the line above for KLD!\n",
    "    \n",
    "    return mean_errors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute the estimation errors\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "rs_errs = {}\n",
    "lw_errs = {}\n",
    "gb_errs = {}\n",
    "n_runs = 100\n",
    "sample_counts = array([10, 20, 40, 80, 160, 320, 640, 1280])\n",
    "\n",
    "for t, o in zip([0, 0, 1, 1], [0, 1, 0, 1]):\n",
    "    rs_errs[(t, o)] = compute_approximation_error(approx_rs, t, o, n_runs, sample_counts)\n",
    "    lw_errs[(t, o)] = compute_approximation_error(approx_lw, t, o, n_runs, sample_counts)\n",
    "    gb_errs[(t, o)] = compute_approximation_error(approx_gibbs, t, o, n_runs, sample_counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot the estimation errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'figure' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-a9af4261a259>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mo\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m     \u001b[0mfigure\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfigsize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m8\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m     \u001b[0mtitle\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Mean Absolute Error, t = %d, o = %d'\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mo\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msample_counts\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrs_errs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mo\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'r'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'Rejection Sampling'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlw\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'figure' is not defined"
     ]
    }
   ],
   "source": [
    "for t, o in zip([0, 0, 1, 1], [0, 1, 0, 1]):\n",
    "    figure(figsize=(10, 8))\n",
    "    title('Mean Absolute Error, t = %d, o = %d' % (t, o))\n",
    "\n",
    "    plot(sample_counts, rs_errs[(t, o)], 'r', label='Rejection Sampling', lw=2)\n",
    "    plot(sample_counts, lw_errs[(t, o)], 'g', label='Likelihood Weighting', lw=2)\n",
    "    plot(sample_counts, gb_errs[(t, o)], 'b', label='Gibbs Sampling', lw=2)   \n",
    "    \n",
    "    legend()\n",
    "    xscale('log')\n",
    "    xlim(sample_counts.min(), sample_counts.max())\n",
    "    xlabel('Number of samples')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.12, 0.88]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.4882418812989921, 0.51175811870100796]"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "approx_rs(0, 0, 100)\n",
    "approx_lw(0, 0, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
