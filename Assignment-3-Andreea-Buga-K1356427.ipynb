{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "%pylab inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 3 - Parameter Learning\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading data from a text file\n",
    "\n",
    "The following cell loads the data stored in the text files \"train.txt\" and \"test.txt\". This results in two NumPy arrays with shapes 500x5 (train.txt) and 5000x5 (test.txt) - 500 and 5000 samples of the following 5 random variables:\n",
    "\n",
    "Column 0: S ... stress (false (0) or true (1))     \n",
    "Column 1: E ... easily catches cold (false (0) or true (1))  \n",
    "Column 2: G ... genetic disposition (false (0) or true (1))   \n",
    "Column 3: I ... increased blood pressure (false (0) or true (1))   \n",
    "Column 4: H ... heart attack (false (0) or true (1))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(500L, 5L)\n",
      "(5000L, 5L)\n"
     ]
    }
   ],
   "source": [
    "# load the training dataset Y. Note: the file \"train.txt\" has to be in the same directory you started the ipython notebook server in\n",
    "Y = np.loadtxt('train.txt', dtype=int)\n",
    "print Y.shape\n",
    "# print Y[:,0]\n",
    "# load the training dataset Z (used for last exercise). Again, the file has to be in correct directory.\n",
    "Z = np.loadtxt('test.txt', dtype=int)\n",
    "print Z.shape\n",
    "\n",
    "# row indices of the random variables\n",
    "row_index = {\"_s_\" : 0, \"_e_\" : 1, \"_g_\" : 2, \"_i_\" : 3, \"_h_\" : 4}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper functions\n",
    "\n",
    "For each shape of the probability table there is a corresponding sample taking the row indices and returning the probability table. Those will be further use for computing the probabilities for each model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Learning for 1D Probability Distribution Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def mle_1d(var1_column):\n",
    "    \"\"\" \n",
    "    Calculates the probability distribution\n",
    "    of a variable given the training data\n",
    "    :param var1_column: column index of the random variable\n",
    "    :returns: Numpy array containing the probability distribution learned from the training data\n",
    "    \"\"\"\n",
    "    count_pos = 0\n",
    "    var1_val = Y[:, var1_column]\n",
    "    for i in range(0, var1_val.size):\n",
    "        if var1_val[i] == 1:\n",
    "            count_pos += 1\n",
    "            \n",
    "    return [double(var1_val.size-count_pos)/var1_val.size, double(count_pos)/var1_val.size]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def mle_2d(var1_column, var2_column):\n",
    "    \"\"\" \n",
    "    Calculates the probability distribution of a conditional probability\n",
    "    P(var1|var2)\n",
    "    :param var1_column: column index of the first random variable\n",
    "    :param var2_column: column index of the second random variable\n",
    "    :returns: Numpy array containing the probability distribution learned from the training data\n",
    "    \"\"\"\n",
    "    if (var1_column == var2_column) :\n",
    "        return \"Invalid input parameters. Column indices should be different\"\n",
    "    var1_val = Y[:, var1_column]\n",
    "    var2_val = Y[:, var2_column]\n",
    "    \n",
    "    mle_pd = array([[0, 0],\n",
    "              [0, 0]])\n",
    "    for i in range(0, var1_val.size):\n",
    "        mle_pd [var1_val[i]][var2_val[i]] += 1 \n",
    "        \n",
    "    return array([[double(mle_pd[0][0])/np.sum(mle_pd[:, 0]), double(mle_pd[0][1])/np.sum(mle_pd[:, 1])],\n",
    "            [double(mle_pd[1][0])/np.sum(mle_pd[:, 0]), double(mle_pd[1][1])/np.sum(mle_pd[:, 1])]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def mle_3d(var1_column, var2_column, var3_column):\n",
    "    \"\"\" \n",
    "    Calculates the probability distribution of a conditional probability\n",
    "    P(var1|var2, var3)\n",
    "    :param var1_column: column index of the first random variable\n",
    "    :param var2_column: column index of the second random variable\n",
    "    :param var3_column: column index of the third random variable\n",
    "    :returns: Numpy array containing the probability distribution learned from the training data\n",
    "    \"\"\"\n",
    "    if (var1_column == var2_column or var1_column == var3_column or var2_column == var3_column) :\n",
    "        return \"Invalid input parameters. Column indices should be different\"\n",
    "    \n",
    "    var1_val = Y[:, var1_column]\n",
    "    var2_val = Y[:, var2_column]\n",
    "    var3_val = Y[:, var3_column]\n",
    "    \n",
    "    mle_pd = array ([[[0.0, 0.0],\n",
    "                    [0.0, 0.0]],\n",
    "                   [[0.0, 0.0],\n",
    "                   [0.0, 0.0]]])\n",
    "    \n",
    "    for i in range(0, var1_val.size):\n",
    "        mle_pd [var1_val[i]][var2_val[i]][var3_val[i]] += 1\n",
    "    \n",
    "    for i in range(0, 2):\n",
    "        for j in range(0, 2):\n",
    "            sum = np.sum(mle_pd[:, i, j])\n",
    "            for k in range (0, 2):\n",
    "                x = double(mle_pd[k][i][j])/sum\n",
    "                mle_pd[k][i][j] = double(mle_pd[k][i][j])/sum\n",
    "                 \n",
    "    return mle_pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 1\n",
    "\n",
    "Learn probability tables for the first model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probability distribution table for P(S):  [0.80600000000000005, 0.19400000000000001]\n",
      "Probability distribution table for P(E):  [0.90400000000000003, 0.096000000000000002]\n",
      "Probability distribution table for P(G):  [0.88400000000000001, 0.11600000000000001]\n",
      "Probability distribution table for P(I):  [0.83399999999999996, 0.16600000000000001]\n",
      "Probability distribution table for P(H):  [0.90000000000000002, 0.10000000000000001]\n"
     ]
    }
   ],
   "source": [
    "# Displaying information about the PDs of the first model\n",
    "S = mle_1d(row_index[\"_s_\"])\n",
    "E = mle_1d(row_index[\"_e_\"])\n",
    "G = mle_1d(row_index[\"_g_\"])\n",
    "I = mle_1d(row_index[\"_i_\"])\n",
    "H = mle_1d(row_index[\"_h_\"])\n",
    "print 'Probability distribution table for P(S): ', S\n",
    "print 'Probability distribution table for P(E): ', E\n",
    "print 'Probability distribution table for P(G): ', G\n",
    "print 'Probability distribution table for P(I): ', I\n",
    "print 'Probability distribution table for P(H): ', H"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Log Likelihood of the first model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-970.811902926\n",
      "-9545.45920494\n"
     ]
    }
   ],
   "source": [
    "def ml1_loglik(data):\n",
    "    l = 0\n",
    "    sample_no = data[:, 0].size\n",
    "    for i in range(0, sample_no):\n",
    "        row = data[i]\n",
    "        sample_prob = S[row[0]] * E[row[1]] * G[row[2]] * I[row[3]] * H[row[4]]\n",
    "        l += np.log(sample_prob)\n",
    "    return l\n",
    "\n",
    "print ml1_loglik(Y)\n",
    "print ml1_loglik(Z)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 2\n",
    "\n",
    "Learn probability tables for the second model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probability distribution table for P(S):  [0.80600000000000005, 0.19400000000000001]\n",
      "Probability distribution table for P(E|S):  [[ 0.92059553  0.83505155]\n",
      " [ 0.07940447  0.16494845]]\n",
      "Probability distribution table for P(G):  [0.88400000000000001, 0.11600000000000001]\n",
      "Probability distribution table for P(I|G, S):  [[[ 0.90960452  0.67045455]\n",
      "  [ 0.69387755  0.22222222]]\n",
      "\n",
      " [[ 0.09039548  0.32954545]\n",
      "  [ 0.30612245  0.77777778]]]\n",
      "Probability distribution table for P(H|I):  [[ 0.90647482  0.86746988]\n",
      " [ 0.09352518  0.13253012]]\n"
     ]
    }
   ],
   "source": [
    "# Displaying information about the PDs of the second model\n",
    "E_S = mle_2d(row_index[\"_e_\"], row_index[\"_s_\"])\n",
    "I_GS = mle_3d(row_index[\"_i_\"], row_index[\"_g_\"], row_index[\"_s_\"])\n",
    "H_I = mle_2d(row_index[\"_h_\"], row_index[\"_i_\"])\n",
    "print 'Probability distribution table for P(S): ', S\n",
    "print 'Probability distribution table for P(E|S): ', E_S\n",
    "print 'Probability distribution table for P(G): ', G\n",
    "print 'Probability distribution table for P(I|G, S): ', I_GS\n",
    "print 'Probability distribution table for P(H|I): ', H_I"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Log Likelihood of the second model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-940.762978609\n",
      "-9216.89949044\n"
     ]
    }
   ],
   "source": [
    "def ml2_loglik(data):\n",
    "    l = 0\n",
    "    sample_no = data[:, 0].size\n",
    "    for i in range(0, sample_no):\n",
    "        row = data[i]\n",
    "        sample_prob = S[row[0]] * E_S[row[1]][row[0]] * G[row[2]] * I_GS[row[3]][row[2]][row[0]] * H_I[row[4]][row[3]]\n",
    "        #\n",
    "        l += np.log(sample_prob)\n",
    "    return l\n",
    "\n",
    "print ml2_loglik(Y)\n",
    "print ml2_loglik(Z)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 3\n",
    "\n",
    "Learn probability tables for the third model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probability distribution table for P(G):  [0.88400000000000001, 0.11600000000000001]\n",
      "Probability distribution table for P(S|G):  [[ 0.80090498  0.84482759]\n",
      " [ 0.19909502  0.15517241]]\n",
      "Probability distribution table for P(E|S, I):  [[[ 0.91853933  0.93617021]\n",
      "  [ 0.81967213  0.86111111]]\n",
      "\n",
      " [[ 0.08146067  0.06382979]\n",
      "  [ 0.18032787  0.13888889]]]\n",
      "Probability distribution table for P(I|G, S):  [[[ 0.90960452  0.67045455]\n",
      "  [ 0.69387755  0.22222222]]\n",
      "\n",
      " [[ 0.09039548  0.32954545]\n",
      "  [ 0.30612245  0.77777778]]]\n",
      "Probability distribution table for P(H|I, E):  [[[ 0.9071618  0.9      ]\n",
      "  [ 0.88       0.75     ]]\n",
      "\n",
      " [[ 0.0928382  0.1      ]\n",
      "  [ 0.12       0.25     ]]]\n"
     ]
    }
   ],
   "source": [
    "# Displaying information about the PDs of the third model\n",
    "S_G = mle_2d(row_index[\"_s_\"], row_index[\"_g_\"])\n",
    "E_SI = mle_3d(row_index[\"_e_\"], row_index[\"_s_\"], row_index[\"_i_\"])\n",
    "H_IE = mle_3d(row_index[\"_h_\"], row_index[\"_i_\"], row_index[\"_e_\"] )\n",
    "print 'Probability distribution table for P(G): ', G\n",
    "print 'Probability distribution table for P(S|G): ', S_G\n",
    "print 'Probability distribution table for P(E|S, I): ', E_SI\n",
    "print 'Probability distribution table for P(I|G, S): ', I_GS\n",
    "print 'Probability distribution table for P(H|I, E): ', H_IE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Log Likelihood of the second model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-939.734032094\n",
      "-9226.91241436\n"
     ]
    }
   ],
   "source": [
    "def ml3_loglik(data):\n",
    "    l = 0\n",
    "    sample_no = data[:, 0].size\n",
    "    for i in range(0, sample_no):\n",
    "        row = data[i]\n",
    "        sample_prob = G[row[2]] * S_G[row[0]][row[2]] * E_SI[row[1]][row[0]][row[3]] * I_GS[row[3]][row[2]][row[0]] * H_IE[row[4]][row[3]][row[1]]\n",
    "        \n",
    "        l += np.log(sample_prob)\n",
    "    return l\n",
    "\n",
    "print ml3_loglik(Y)\n",
    "print ml3_loglik(Z)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparison\n",
    "\n",
    "## Part A - Comparison of the log likelihood of models on the training data\n",
    "\n",
    "## Part B - Comparison of the log likelihood of models on the test data\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
